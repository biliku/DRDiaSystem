import os
os.environ['ALBUMENTATIONS_DISABLE_VERSION_CHECK'] = '1'
import pandas as pd
import numpy as np
import cv2
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler
from sklearn.metrics import cohen_kappa_score, confusion_matrix, classification_report
import albumentations as A
from albumentations.pytorch import ToTensorV2
from efficientnet_pytorch import EfficientNet
from tqdm import tqdm
import matplotlib.pyplot as plt
import seaborn as sns
from torch.cuda.amp import GradScaler
from torch.optim.lr_scheduler import ReduceLROnPlateau
import torch.multiprocessing
import logging
from datetime import datetime
from collections import Counter
import torch.nn.functional as F

# --- å…¨å±€å¸¸é‡å’Œé…ç½® ---
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False

IMG_SIZE = 512
BATCH_SIZE = 4
NUM_WORKERS = 4
NUM_EPOCHS = 50
LEARNING_RATE = 1e-4
NUM_CLASSES = 5
MODEL_SAVE_PATH = "best_efficientnetb3_aptos.pth"
DATA_ROOT = 'F:\\DRDiaSys\\django\\DRDiaSys\\datasets\\dataset\\aptos2019_preprocessed'
TRAIN_CSV_PATH = os.path.join(DATA_ROOT, 'train.csv')
VAL_CSV_PATH = os.path.join(DATA_ROOT, 'valid.csv')
TEST_CSV_PATH = os.path.join(DATA_ROOT, 'test.csv')

TRAIN_IMAGE_DIR = os.path.join(DATA_ROOT, 'train_images_processed')
VAL_IMAGE_DIR = os.path.join(DATA_ROOT, 'val_images_processed')
TEST_IMAGE_DIR = os.path.join(DATA_ROOT, 'test_images_processed')

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# --- æ—¥å¿—è®¾ç½® ---
def setup_logger():
    log_dir = 'logs'
    os.makedirs(log_dir, exist_ok=True)
    log_file = os.path.join(log_dir, f'training_balanced_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log')
    for handler in logging.root.handlers[:]: 
        logging.root.removeHandler(handler)
    logging.basicConfig(
        level=logging.INFO, 
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[logging.FileHandler(log_file), logging.StreamHandler()]
    )
    return logging.getLogger(__name__)

logger = None

# --- ä¿®æ”¹1: æ•°æ®å¢å¼ºç­–ç•¥ - é’ˆå¯¹å°‘æ•°ç±»çš„é¢å¤–å¢å¼º ---
def create_balanced_dataset(df, multiplier_dict={0: 1, 1: 8, 2: 4, 3: 15, 4: 20}):
    """é€šè¿‡æ•°æ®å¢å¼ºå¹³è¡¡æ•°æ®é›†"""
    balanced_df = []
    
    for class_id in range(NUM_CLASSES):
        class_samples = df[df['diagnosis'] == class_id]
        multiplier = multiplier_dict.get(class_id, 1)
        
        # é‡å¤æ ·æœ¬
        for _ in range(multiplier):
            balanced_df.append(class_samples)
    
    result_df = pd.concat(balanced_df, ignore_index=True).sample(frac=1).reset_index(drop=True)
    logger.info(f"å¹³è¡¡åæ•°æ®é›†å¤§å°: {len(result_df)}")
    logger.info(f"å¹³è¡¡åç±»åˆ«åˆ†å¸ƒ:\n{result_df['diagnosis'].value_counts().sort_index()}")
    
    return result_df

# --- ä¿®æ”¹2: ææ¿€è¿›çš„ç±»åˆ«æƒé‡è®¡ç®— ---
def calculate_class_weights(df):
    """ä½¿ç”¨å¹³æ–¹æ ¹å€’æ•°è®¡ç®—ææ¿€è¿›çš„ç±»åˆ«æƒé‡"""
    class_counts = df['diagnosis'].value_counts().sort_index()
    total_samples = len(df)
    weights = []
    
    logger.info("=== ææ¿€è¿›ç±»åˆ«æƒé‡è®¡ç®— ===")
    for i in range(NUM_CLASSES):
        if i in class_counts.index:
            count = class_counts[i]
            # ææ¿€è¿›ï¼šä½¿ç”¨å¹³æ–¹æ ¹å€’æ•°
            base_weight = total_samples / (NUM_CLASSES * count)
            aggressive_weight = np.sqrt(base_weight) * 2  # å¹³æ–¹æ ¹ + é¢å¤–æ”¾å¤§
            weights.append(aggressive_weight)
            logger.info(f"ç±»åˆ« {i}: {count} æ ·æœ¬, æƒé‡: {aggressive_weight:.4f}")
        else:
            weights.append(1.0)
            logger.info(f"ç±»åˆ« {i}: 0 æ ·æœ¬, æƒé‡: 1.0000")
    
    return torch.FloatTensor(weights)

# --- ä¿®æ”¹3: ä¸‰é˜¶æ®µæ¸è¿›æŸå¤±å‡½æ•° ---
class ProgressiveLoss(nn.Module):
    def __init__(self, class_weights):
        super().__init__()
        self.class_weights = class_weights
        self.stage = 1  # é»˜è®¤ä»é˜¶æ®µ1å¼€å§‹

    def set_stage(self, stage):
        self.stage = stage

    def forward(self, outputs, targets):
        mse = F.mse_loss(outputs, targets, reduction='none')
        sample_weights = torch.ones_like(targets)
        for i, weight in enumerate(self.class_weights):
            sample_weights[targets == i] = weight

        if self.stage == 1:
            # é˜¶æ®µ1: æ¸©å’Œçš„åŠ æƒMSE
            weighted_mse = mse.squeeze() * sample_weights
            return weighted_mse.mean()
        
        elif self.stage == 2:
            # é˜¶æ®µ2: ä¸­ç­‰Focal Loss
            focal_weight = 1.5 * (mse.detach() + 1e-8) ** 1.0
            combined_weight = sample_weights * focal_weight.squeeze()
            weighted_mse = mse.squeeze() * combined_weight
            return weighted_mse.mean()
        
        else:  # stage == 3
            # é˜¶æ®µ3: ææ¿€è¿›Focal Loss
            focal_weight = 3.0 * (mse.detach() + 1e-8) ** 1.5
            combined_weight = sample_weights * focal_weight.squeeze()
            weighted_mse = mse.squeeze() * combined_weight
            return weighted_mse.mean()

# --- ä¿®æ”¹4: è‡ªé€‚åº”é˜ˆå€¼ç³»ç»Ÿ ---
class AdaptiveThresholdSystem:
    def __init__(self):
        self.thresholds = [0.5, 1.5, 2.5, 3.5]  # åˆå§‹é˜ˆå€¼
        self.correct_predictions = [0] * NUM_CLASSES
        self.total_samples = [1] * NUM_CLASSES  # é¿å…é™¤é›¶
        
    def update_stats(self, true_labels, pred_labels):
        """æ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
        for true_label, pred_label in zip(true_labels, pred_labels):
            # å°† numpy.float32 è½¬æ¢ä¸ºæ•´æ•°
            true_label = int(true_label)
            pred_label = int(pred_label)
            
            self.total_samples[true_label] += 1
            if true_label == pred_label:
                self.correct_predictions[true_label] += 1
    
    def adapt_thresholds(self):
        """æ ¹æ®å„ç±»åˆ«å‡†ç¡®ç‡åŠ¨æ€è°ƒæ•´é˜ˆå€¼"""
        accuracy_rates = [correct/total for correct, total in zip(self.correct_predictions, self.total_samples)]
        
        # å¯¹äºå‡†ç¡®ç‡ä½çš„ç±»åˆ«ï¼Œè°ƒæ•´é˜ˆå€¼
        for i in range(len(self.thresholds)):
            if accuracy_rates[i] < 0.7:  # å¦‚æœå‡†ç¡®ç‡ä½äº70%
                # é™ä½é˜ˆå€¼ï¼Œä½¿æ¨¡å‹æ›´å®¹æ˜“é¢„æµ‹ä¸ºè¯¥ç±»åˆ«
                self.thresholds[i] *= 0.95
            elif accuracy_rates[i] > 0.9:  # å¦‚æœå‡†ç¡®ç‡é«˜äº90%
                # æé«˜é˜ˆå€¼ï¼Œä½¿æ¨¡å‹æ›´è°¨æ…
                self.thresholds[i] *= 1.05
                
        # ç¡®ä¿é˜ˆå€¼åœ¨åˆç†èŒƒå›´å†…
        self.thresholds = [max(0.1, min(3.9, t)) for t in self.thresholds]
        
        # é‡ç½®ç»Ÿè®¡ä¿¡æ¯
        self.correct_predictions = [0] * NUM_CLASSES
        self.total_samples = [1] * NUM_CLASSES
    
    def get_thresholds(self):
        """è·å–å½“å‰é˜ˆå€¼"""
        return self.thresholds

# å…¨å±€è‡ªé€‚åº”é˜ˆå€¼ç³»ç»Ÿ
adaptive_threshold_system = AdaptiveThresholdSystem()

# --- ä¿®æ”¹5: æ”¹è¿›çš„è¾“å‡ºè½¬æ¢å‡½æ•° ---
def convert_outputs_to_class(outputs, use_adaptive=True):
    """ä½¿ç”¨è‡ªé€‚åº”é˜ˆå€¼è¿›è¡Œåˆ†ç±»"""
    if use_adaptive:
        thresholds = adaptive_threshold_system.thresholds
    else:
        thresholds = [0.5, 1.5, 2.5, 3.5]
    
    outputs = torch.clamp(outputs.squeeze(dim=1), 0, 4)
    classes = torch.zeros_like(outputs, dtype=torch.long)
    
    for i, threshold in enumerate(thresholds):
        classes = torch.where(outputs > threshold, i+1, classes)
    
    return classes

# --- æ•°æ®é›†å®šä¹‰ï¼ˆä¿æŒä¸å˜ï¼‰---
class AptosDataset(Dataset):
    def __init__(self, df, transform=None, image_dir=None):
        self.df = df.reset_index(drop=True)
        self.transform = transform
        self.image_dir = image_dir

    def __len__(self): 
        return len(self.df)

    def __getitem__(self, idx):
        img_name = self.df.loc[idx, 'id_code'] + '.png'
        img_path = os.path.join(self.image_dir, img_name)
        label = self.df.loc[idx, 'diagnosis']
        
        try:
            image = cv2.imread(img_path)
            if image is None: 
                raise RuntimeError(f"æ— æ³•è¯»å–å›¾åƒ: {img_path}")
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            if self.transform: 
                image = self.transform(image=image)['image']
            
            return image, torch.tensor(label, dtype=torch.float32).unsqueeze(0)
        
        except Exception as e:
            if logger: 
                logger.error(f"åŠ è½½å›¾åƒ {img_path} æ—¶å‡ºé”™: {e}")
            default_image = np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)
            if self.transform: 
                default_image = self.transform(image=default_image)['image']
            return default_image, torch.tensor(0.0, dtype=torch.float32).unsqueeze(0)

# --- æ•°æ®å¢å¼ºå®šä¹‰ï¼ˆä¿æŒä¸å˜ï¼‰---
IMAGENET_MEAN = (0.485, 0.456, 0.406)
IMAGENET_STD = (0.229, 0.224, 0.225)

train_transform = A.Compose([
    A.HorizontalFlip(p=0.5),
    A.VerticalFlip(p=0.5),
    A.Rotate(limit=45, p=0.7),
    A.Affine(scale=(0.8, 1.2), translate_percent=(-0.1, 0.1), rotate=(-15, 15), shear=(-10, 10), p=0.7),
    A.OneOf([
        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=1),
        A.RandomGamma(gamma_limit=(80, 120), p=1),
        A.CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), p=1)
    ], p=0.5),
    A.OneOf([
        A.GaussNoise(p=1), 
        A.GaussianBlur(blur_limit=(3, 7), p=1), 
        A.MotionBlur(blur_limit=(3, 7), p=1)
    ], p=0.3),
    A.OneOf([
        A.OpticalDistortion(distort_limit=0.2, p=1), 
        A.ElasticTransform(alpha=1, sigma=50, p=1), 
        A.CoarseDropout(p=0.5)
    ], p=0.3),
    A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),
    ToTensorV2(),
])

val_test_transform = A.Compose([
    A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),
    ToTensorV2(),
])

# --- è¯¦ç»†è¯„ä¼°å‡½æ•°ï¼ˆä¿æŒä¸å˜ï¼‰---
def detailed_class_evaluation(all_labels, all_preds):
    """è¯¦ç»†çš„æ¯ç±»åˆ«è¯„ä¼°"""
    logger.info("\n=== è¯¦ç»†ç±»åˆ«è¯„ä¼° ===")
    
    for class_id in range(NUM_CLASSES):
        class_mask = np.array(all_labels) == class_id
        if class_mask.any():
            total_class_samples = class_mask.sum()
            class_preds = np.array(all_preds)[class_mask]
            correct_preds = np.sum(class_preds == class_id)
            class_accuracy = correct_preds / total_class_samples
            
            pred_distribution = {}
            for pred_class in range(NUM_CLASSES):
                count = np.sum(class_preds == pred_class)
                pred_distribution[pred_class] = count
            
            logger.info(f"ç±»åˆ« {class_id}: {correct_preds}/{total_class_samples} = {class_accuracy:.4f}")
            logger.info(f"  é¢„æµ‹åˆ†å¸ƒ: {pred_distribution}")
        else:
            logger.info(f"ç±»åˆ« {class_id}: æ— æµ‹è¯•æ ·æœ¬")
    
    report = classification_report(all_labels, all_preds, target_names=[f'Class_{i}' for i in range(NUM_CLASSES)])
    logger.info(f"\nåˆ†ç±»æŠ¥å‘Š:\n{report}")

# --- ä¿®æ”¹6: ä¸‰é˜¶æ®µè®­ç»ƒå‡½æ•° ---
def train_one_epoch(model, dataloader, criterion, optimizer, scaler, device, epoch, total_epochs):
    model.train()
    running_loss, all_preds, all_labels = 0.0, [], []
    pbar = tqdm(dataloader, desc=f"Epoch {epoch+1}/{total_epochs} [è®­ç»ƒ]", leave=False, position=0)
    
    # åŠ¨æ€è°ƒæ•´æŸå¤±å‡½æ•°é˜¶æ®µ
    if hasattr(criterion, 'set_stage'):
        if epoch < total_epochs * 0.3:
            criterion.set_stage(1)
        elif epoch < total_epochs * 0.7:
            criterion.set_stage(2)
        else:
            criterion.set_stage(3)
    
    for images, labels in pbar:
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()
        
        with torch.amp.autocast('cuda'):
            outputs = model(images)
            loss = criterion(outputs, labels)
        
        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()
        
        running_loss += loss.item() * images.size(0)
        
        preds = convert_outputs_to_class(outputs, use_adaptive=True)
        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.squeeze(dim=1).cpu().numpy())
        
        pbar.set_postfix({
            'loss': f'{loss.item():.4f}', 
            'lr': f'{optimizer.param_groups[0]["lr"]:.2e}'
        })
    
    # æ›´æ–°è‡ªé€‚åº”é˜ˆå€¼ç³»ç»Ÿ
    adaptive_threshold_system.update_stats(all_labels, all_preds)
    if epoch % 5 == 0:  # æ¯5è½®è°ƒæ•´ä¸€æ¬¡é˜ˆå€¼
        adaptive_threshold_system.adapt_thresholds()
        
    if not all_labels: 
        return 0.0, 0.0
    
    avg_loss = running_loss / len(all_labels)
    kappa = cohen_kappa_score(all_labels, all_preds, weights='quadratic')
    
    return avg_loss, kappa

def validate_one_epoch(model, dataloader, criterion, device, epoch):
    model.eval()
    running_loss, all_preds, all_labels = 0.0, [], []
    pbar = tqdm(dataloader, desc=f"Epoch {epoch+1}/{NUM_EPOCHS} [éªŒè¯]", leave=False, position=0)
    
    with torch.no_grad():
        for images, labels in pbar:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            
            running_loss += loss.item() * images.size(0)
            
            preds = convert_outputs_to_class(outputs, use_adaptive=True)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.squeeze(dim=1).cpu().numpy())
            
            pbar.set_postfix({'loss': f'{loss.item():.4f}'})
            
    if not all_labels: 
        return 0.0, 0.0
    
    avg_loss = running_loss / len(all_labels)
    kappa = cohen_kappa_score(all_labels, all_preds, weights='quadratic')
    
    return avg_loss, kappa

def evaluate_model(model, dataloader, device, model_path=None):
    if model_path and os.path.exists(model_path):
        model.load_state_dict(torch.load(model_path, map_location=device))
        logger.info(f"å·²åŠ è½½æ¨¡å‹: {model_path}")
    
    model.to(device)
    model.eval()
    all_preds, all_labels = [], []
    
    with torch.no_grad():
        for images, labels in tqdm(dataloader, desc="è¯„ä¼°ä¸­", leave=False):
            images = images.to(device)
            outputs = model(images)
            
            preds = convert_outputs_to_class(outputs, use_adaptive=True)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.squeeze(dim=1).cpu().numpy())
    
    kappa = cohen_kappa_score(all_labels, all_preds, weights='quadratic')
    accuracy = np.mean(np.array(all_preds) == np.array(all_labels))
    conf_mat = confusion_matrix(all_labels, all_preds, labels=range(NUM_CLASSES))
    
    logger.info(f"\n=== è¯„ä¼°ç»“æœ ===")
    logger.info(f"æ•´ä½“å‡†ç¡®ç‡: {accuracy:.4f}")
    logger.info(f"Quadratic Kappa: {kappa:.4f}")
    logger.info(f"\næ··æ·†çŸ©é˜µ:\n{conf_mat}")
    
    detailed_class_evaluation(all_labels, all_preds)
    
    plt.figure(figsize=(10, 8))
    sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', 
                xticklabels=range(NUM_CLASSES), yticklabels=range(NUM_CLASSES))
    plt.xlabel('é¢„æµ‹æ ‡ç­¾')
    plt.ylabel('çœŸå®æ ‡ç­¾')
    plt.title('æ··æ·†çŸ©é˜µ')
    plt.tight_layout()
    plt.savefig('confusion_matrix_balanced_v2.png', dpi=300, bbox_inches='tight')
    plt.close()

def main():
    global logger
    logger = setup_logger()
    
    if not torch.cuda.is_available(): 
        logger.error("æœªæ£€æµ‹åˆ°GPU!")
        return
    
    logger.info(f"ä½¿ç”¨GPU: {torch.cuda.get_device_name(0)}")

    train_df_orig = pd.read_csv(TRAIN_CSV_PATH)
    val_df = pd.read_csv(VAL_CSV_PATH)
    test_df = pd.read_csv(TEST_CSV_PATH)
    
    logger.info("\n=== åŸå§‹è®­ç»ƒé›†ç±»åˆ«åˆ†å¸ƒ ===")
    logger.info(f"{train_df_orig['diagnosis'].value_counts().sort_index()}")
    
    # ä¿®æ”¹7: åˆ›å»ºå¹³è¡¡æ•°æ®é›†
    balanced_train_df = create_balanced_dataset(train_df_orig)
    
    class_weights = calculate_class_weights(train_df_orig)  # ä»åŸºäºåŸå§‹åˆ†å¸ƒè®¡ç®—æƒé‡
    
    train_dataset = AptosDataset(df=balanced_train_df, transform=train_transform, image_dir=TRAIN_IMAGE_DIR)
    val_dataset = AptosDataset(df=val_df, transform=val_test_transform, image_dir=VAL_IMAGE_DIR)
    test_dataset = AptosDataset(df=test_df, transform=val_test_transform, image_dir=TEST_IMAGE_DIR)

    train_loader = DataLoader(
        train_dataset, 
        batch_size=BATCH_SIZE, 
        shuffle=True,  # ä½¿ç”¨shuffleè€Œä¸æ˜¯weighted sampler
        num_workers=NUM_WORKERS, 
        pin_memory=True
    )
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)
    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)
    
    logger.info(f"\nDataLoadersåˆ›å»ºå®Œæˆï¼Œä½¿ç”¨å¹³è¡¡æ•°æ®é›† + æ¸è¿›æŸå¤± + è‡ªé€‚åº”é˜ˆå€¼")

    model = EfficientNet.from_pretrained('efficientnet-b3', num_classes=1).to(DEVICE)
    
    # ä¿®æ”¹8: ä½¿ç”¨æ¸è¿›æŸå¤±å‡½æ•°
    criterion = ProgressiveLoss(class_weights.to(DEVICE))
    
    # ä¿®æ”¹9: è°ƒæ•´ä¼˜åŒ–å™¨å‚æ•°
    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-2)
    scaler = torch.amp.GradScaler('cuda')
    
    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=4, min_lr=1e-7)
    
    logger.info(f"\nå¼€å§‹ä¸‰é˜¶æ®µæ¸è¿›è®­ç»ƒ:")
    logger.info(f"é˜¶æ®µ1 (0-30%): æ¸©å’ŒåŠ æƒMSE")
    logger.info(f"é˜¶æ®µ2 (30-70%): ä¸­ç­‰Focal Loss") 
    logger.info(f"é˜¶æ®µ3 (70-100%): ææ¿€è¿›Focal Loss")
    logger.info(f"è‡ªé€‚åº”é˜ˆå€¼ç³»ç»Ÿ: æ¯5è½®æ ¹æ®ç±»åˆ«é”™è¯¯ç‡è°ƒæ•´é˜ˆå€¼")
    
    best_val_kappa = -1.0
    patience, no_improve_epochs = 8, 0
    history = {'train_loss': [], 'val_loss': [], 'train_kappa': [], 'val_kappa': []}

    for epoch in range(NUM_EPOCHS):
        train_loss, train_kappa = train_one_epoch(model, train_loader, criterion, optimizer, scaler, DEVICE, epoch, NUM_EPOCHS)
        val_loss, val_kappa = validate_one_epoch(model, val_loader, criterion, DEVICE, epoch)
        
        scheduler.step(val_kappa)
        
        history['train_loss'].append(train_loss)
        history['val_loss'].append(val_loss)
        history['train_kappa'].append(train_kappa) 
        history['val_kappa'].append(val_kappa)
        
        tqdm.write(f"\nEpoch {epoch+1}/{NUM_EPOCHS} ç»“æœ:")
        tqdm.write(f"  [è®­ç»ƒ] -> æŸå¤±: {train_loss:.4f}, Kappa: {train_kappa:.4f}")
        tqdm.write(f"  [éªŒè¯] -> æŸå¤±: {val_loss:.4f}, Kappa: {val_kappa:.4f}")
        tqdm.write(f"  å½“å‰å­¦ä¹ ç‡: {optimizer.param_groups[0]['lr']:.2e}")
        tqdm.write(f"  å½“å‰é˜ˆå€¼: {adaptive_threshold_system.thresholds}")
        
        if val_kappa > best_val_kappa + 1e-6:
            best_val_kappa = val_kappa
            torch.save(model.state_dict(), MODEL_SAVE_PATH)
            tqdm.write(f"  ğŸ‰ ä¿å­˜æœ€ä½³æ¨¡å‹ - éªŒè¯é›† Kappa: {best_val_kappa:.4f}")
            no_improve_epochs = 0
        else:
            no_improve_epochs += 1
            tqdm.write(f"  éªŒè¯é›† Kappa æœªæå‡ ({no_improve_epochs}/{patience})")
            
            if no_improve_epochs >= patience:
                logger.info(f"\n{patience} è½®æœªæ”¹å–„ï¼Œæå‰åœæ­¢è®­ç»ƒ")
                break

    logger.info("\nè®­ç»ƒå®Œæˆ!")
    
    epochs_ran = range(1, len(history['train_loss']) + 1)
    plt.figure(figsize=(12, 5))
    
    plt.subplot(1, 2, 1)
    plt.plot(epochs_ran, history['train_loss'], label='è®­ç»ƒæŸå¤±')
    plt.plot(epochs_ran, history['val_loss'], label='éªŒè¯æŸå¤±')
    plt.title('æŸå¤±æ›²çº¿ (æ¸è¿›æŸå¤±)')
    plt.xlabel('Epoch')
    plt.ylabel('æŸå¤±')
    plt.legend()
    
    plt.subplot(1, 2, 2)
    plt.plot(epochs_ran, history['train_kappa'], label='è®­ç»ƒKappa')
    plt.plot(epochs_ran, history['val_kappa'], label='éªŒè¯Kappa')
    plt.title('Kappaåˆ†æ•°æ›²çº¿')
    plt.xlabel('Epoch')
    plt.ylabel('Kappaåˆ†æ•°')
    plt.legend()
    
    plt.tight_layout()
    plt.savefig('training_curves.png', dpi=300, bbox_inches='tight')
    plt.close()

    logger.info("\n=== åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æœ€ä½³æ¨¡å‹ ===")
    evaluate_model(model, test_loader, DEVICE, MODEL_SAVE_PATH)
    
    logger.info(f"\n=== è®­ç»ƒå’Œè¯„ä¼°å®Œæˆ ===")
    logger.info(f"æœ€ä½³æ¨¡å‹å·²ä¿å­˜è‡³: {MODEL_SAVE_PATH}")
    logger.info(f"è®­ç»ƒæ›²çº¿å·²ä¿å­˜è‡³: training_curves.png")
    logger.info(f"æ··æ·†çŸ©é˜µå·²ä¿å­˜è‡³: confusion_matrix.png")

if __name__ == '__main__':
    try:
        torch.multiprocessing.set_start_method('spawn', force=True)
    except RuntimeError: 
        pass
    main()
