import os
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler
import torchvision.transforms as transforms
import torchvision.models as models
import pandas as pd
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.utils.class_weight import compute_class_weight
import seaborn as sns
from tqdm import tqdm
import warnings
import albumentations as A
from albumentations.pytorch import ToTensorV2
import cv2
warnings.filterwarnings('ignore')

# --- å…¨å±€å¸¸é‡å’Œé…ç½® ---
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False

IMG_SIZE = 384
BATCH_SIZE = 16  # å‡å°‘batch size
NUM_WORKERS = 4
NUM_EPOCHS = 15  # å¤§å¹…å‡å°‘epoch
LEARNING_RATE = 1e-5  # æ˜¾è‘—é™ä½å­¦ä¹ ç‡
NUM_CLASSES = 5
MODEL_SAVE_PATH = "best_resnet_aptos_improved.pth"
DATA_ROOT = 'F:\\DRDiaSys\\django\\DRDiaSys\\datasets\\dataset\\aptos2019_preprocessed'
TRAIN_CSV_PATH = os.path.join(DATA_ROOT, 'train.csv')
VAL_CSV_PATH = os.path.join(DATA_ROOT, 'valid.csv')
TEST_CSV_PATH = os.path.join(DATA_ROOT, 'test.csv')

TRAIN_IMAGE_DIR = os.path.join(DATA_ROOT, 'train_images_processed')
VAL_IMAGE_DIR = os.path.join(DATA_ROOT, 'val_images_processed')
TEST_IMAGE_DIR = os.path.join(DATA_ROOT, 'test_images_processed')

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ä½¿ç”¨è®¾å¤‡: {DEVICE}")

# --- æœ€å°åŒ–æ•°æ®å¢å¼º ---
class AdvancedDataTransforms:
    def __init__(self):
        # æç®€æ•°æ®å¢å¼º
        self.train_transforms = A.Compose([
            A.Resize(IMG_SIZE, IMG_SIZE),
            A.HorizontalFlip(p=0.3),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2(),
        ])
        
        self.val_transforms = A.Compose([
            A.Resize(IMG_SIZE, IMG_SIZE),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2(),
        ])

# --- æ”¹è¿›çš„æ•°æ®é›†ç±» ---
class ImprovedDRDataset(Dataset):
    def __init__(self, csv_path, image_dir, transform=None, use_albumentations=True):
        self.df = pd.read_csv(csv_path)
        self.image_dir = image_dir
        self.transform = transform
        self.use_albumentations = use_albumentations
        
        # è®¡ç®—ç±»åˆ«æƒé‡
        self.class_counts = self.df['diagnosis'].value_counts().sort_index()
        print(f"ç±»åˆ«åˆ†å¸ƒ: {self.class_counts.to_dict()}")
        
    def __len__(self):
        return len(self.df)
    
    def __getitem__(self, idx):
        image_name = self.df.iloc[idx]['id_code']
        if not image_name.endswith('.png'):
            image_name += '.png'
        
        image_path = os.path.join(self.image_dir, image_name)
        
        if self.use_albumentations:
            image = cv2.imread(image_path)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            if self.transform:
                transformed = self.transform(image=image)
                image = transformed['image']
        else:
            image = Image.open(image_path).convert('RGB')
            if self.transform:
                image = self.transform(image)
        
        label = int(self.df.iloc[idx]['diagnosis'])
        return image, label
    
    def get_class_weights(self):
        """è®¡ç®—ç±»åˆ«æƒé‡ç”¨äºæŸå¤±å‡½æ•°"""
        labels = self.df['diagnosis'].values
        class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)
        return torch.FloatTensor(class_weights)

# --- æåº¦ç®€åŒ–çš„æ¨¡å‹æ¶æ„ ---
class ImprovedResNetDR(nn.Module):
    def __init__(self, num_classes=5, pretrained=True, dropout_rate=0.7):
        super(ImprovedResNetDR, self).__init__()
        
        # ä½¿ç”¨ResNet34
        self.backbone = models.resnet34(pretrained=pretrained)
        
        # å†»ç»“å‰é¢çš„å±‚
        for name, param in self.backbone.named_parameters():
            if 'layer3' not in name and 'layer4' not in name and 'fc' not in name:
                param.requires_grad = False
        
        num_features = self.backbone.fc.in_features
        
        # ç®€åŒ–åˆ†ç±»å¤´
        self.backbone.fc = nn.Sequential(
            nn.Dropout(dropout_rate),
            nn.Linear(num_features, 128),
            nn.ReLU(inplace=True),
            nn.BatchNorm1d(128),
            nn.Dropout(dropout_rate),
            nn.Linear(128, num_classes)
        )
        
    def forward(self, x):
        return self.backbone(x)

# --- æ··åˆæŸå¤±å‡½æ•° ---
class MixedLoss(nn.Module):
    def __init__(self, alpha=0.7, class_weights=None):
        super(MixedLoss, self).__init__()
        self.alpha = alpha
        self.ce_loss = nn.CrossEntropyLoss(weight=class_weights)
        self.mse_loss = nn.MSELoss()
        
    def forward(self, pred, target):
        ce = self.ce_loss(pred, target)
        # å°†åˆ†ç±»é—®é¢˜è§†ä¸ºå›å½’é—®é¢˜
        pred_soft = F.softmax(pred, dim=1)
        target_reg = target.float().unsqueeze(1)
        pred_reg = torch.sum(pred_soft * torch.arange(5).float().to(pred.device), dim=1, keepdim=True)
        mse = self.mse_loss(pred_reg, target_reg)
        
        return self.alpha * ce + (1 - self.alpha) * mse

# --- æ”¹è¿›çš„è®­ç»ƒå‡½æ•° ---
def train_model_with_early_stopping(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, patience=3):
    train_losses = []
    val_losses = []
    train_accuracies = []
    val_accuracies = []
    best_val_acc = 0.0
    early_stop_counter = 0
    best_epoch = 0
    
    for epoch in range(num_epochs):
        print(f'\nEpoch {epoch+1}/{num_epochs}')
        print('-' * 40)
        
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        running_loss = 0.0
        correct = 0
        total = 0
        
        train_bar = tqdm(train_loader, desc='è®­ç»ƒä¸­')
        for images, labels in train_bar:
            images, labels = images.to(DEVICE), labels.to(DEVICE)
            
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            
            loss.backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            optimizer.step()
            
            running_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
            
            train_bar.set_postfix({
                'Loss': f'{loss.item():.4f}',
                'Acc': f'{100.*correct/total:.2f}%'
            })
        
        train_loss = running_loss / len(train_loader)
        train_acc = 100. * correct / total
        train_losses.append(train_loss)
        train_accuracies.append(train_acc)
        
        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_loss = 0.0
        correct = 0
        total = 0
        
        with torch.no_grad():
            val_bar = tqdm(val_loader, desc='éªŒè¯ä¸­')
            for images, labels in val_bar:
                images, labels = images.to(DEVICE), labels.to(DEVICE)
                outputs = model(images)
                loss = criterion(outputs, labels)
                
                val_loss += loss.item()
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
                
                val_bar.set_postfix({
                    'Loss': f'{loss.item():.4f}',
                    'Acc': f'{100.*correct/total:.2f}%'
                })
        
        val_loss = val_loss / len(val_loader)
        val_acc = 100. * correct / total
        val_losses.append(val_loss)
        val_accuracies.append(val_acc)
        
        # å­¦ä¹ ç‡è°ƒåº¦
        if isinstance(scheduler, optim.lr_scheduler.ReduceLROnPlateau):
            scheduler.step(val_loss)
        else:
            scheduler.step()
        
        print(f'è®­ç»ƒæŸå¤±: {train_loss:.4f}, è®­ç»ƒå‡†ç¡®ç‡: {train_acc:.2f}%')
        print(f'éªŒè¯æŸå¤±: {val_loss:.4f}, éªŒè¯å‡†ç¡®ç‡: {val_acc:.2f}%')
        print(f'å½“å‰å­¦ä¹ ç‡: {optimizer.param_groups[0]["lr"]:.2e}')
        
        # è¿‡æ‹Ÿåˆæ£€æµ‹
        overfitting_gap = train_acc - val_acc
        if overfitting_gap > 15:
            print(f'âš ï¸  è¿‡æ‹Ÿåˆè­¦å‘Šï¼šå·®è· {overfitting_gap:.2f}%')
        
        # æ—©åœé€»è¾‘
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            best_epoch = epoch + 1
            torch.save(model.state_dict(), MODEL_SAVE_PATH)
            print(f'âœ… ä¿å­˜æœ€ä½³æ¨¡å‹ï¼ŒéªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}%')
            early_stop_counter = 0
        else:
            early_stop_counter += 1
            
        # ä¸¥é‡è¿‡æ‹Ÿåˆæ—¶æå‰ç»ˆæ­¢
        if overfitting_gap > 30:
            print(f'ğŸš« ä¸¥é‡è¿‡æ‹Ÿåˆï¼Œæå‰ç»ˆæ­¢è®­ç»ƒï¼')
            break
            
        if early_stop_counter >= patience:
            print(f'â¹ï¸  æ—©åœè§¦å‘ï¼')
            break
    
    return train_losses, val_losses, train_accuracies, val_accuracies

# --- TTAè¯„ä¼° ---
def evaluate_model_with_tta(model, test_loader, num_tta=3):
    model.eval()
    all_predictions = []
    all_labels = []
    
    # TTAå˜æ¢
    tta_transforms = [
        A.Compose([
            A.Resize(IMG_SIZE, IMG_SIZE),
            A.HorizontalFlip(p=1.0 if i == 1 else 0.0),
            A.Rotate(limit=5 if i == 2 else 0, p=1.0 if i == 2 else 0.0),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2(),
        ]) for i in range(num_tta)
    ]
    
    with torch.no_grad():
        test_bar = tqdm(test_loader, desc='æµ‹è¯•ä¸­(TTA)')
        for images, labels in test_bar:
            batch_predictions = []
            
            for img, label in zip(images, labels):
                img_np = img.permute(1, 2, 0).numpy()
                img_np = (img_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406]))
                img_np = np.clip(img_np * 255, 0, 255).astype(np.uint8)
                
                tta_outputs = []
                for transform in tta_transforms:
                    transformed = transform(image=img_np)
                    tta_img = transformed['image'].unsqueeze(0).to(DEVICE)
                    output = model(tta_img)
                    tta_outputs.append(F.softmax(output, dim=1))
                
                avg_output = torch.mean(torch.cat(tta_outputs, dim=0), dim=0)
                predicted = torch.argmax(avg_output).cpu().numpy()
                batch_predictions.append(predicted)
                all_labels.append(label.numpy())
            
            all_predictions.extend(batch_predictions)
    
    accuracy = accuracy_score(all_labels, all_predictions)
    class_names = ['æ— ç—…å˜', 'è½»åº¦', 'ä¸­åº¦', 'é‡åº¦', 'å¢æ®–æ€§']
    report = classification_report(all_labels, all_predictions, 
                                 target_names=class_names, 
                                 output_dict=True)
    
    return accuracy, all_predictions, all_labels, report

# --- ä¸»å‡½æ•° ---
def main():
    # åˆ›å»ºæ•°æ®å˜æ¢
    transforms_obj = AdvancedDataTransforms()
    
    # åˆ›å»ºæ•°æ®é›†
    print("æ­£åœ¨åŠ è½½æ•°æ®é›†...")
    train_dataset = ImprovedDRDataset(TRAIN_CSV_PATH, TRAIN_IMAGE_DIR, transforms_obj.train_transforms)
    val_dataset = ImprovedDRDataset(VAL_CSV_PATH, VAL_IMAGE_DIR, transforms_obj.val_transforms)
    test_dataset = ImprovedDRDataset(TEST_CSV_PATH, TEST_IMAGE_DIR, transforms_obj.val_transforms)
    
    # è·å–ç±»åˆ«æƒé‡
    class_weights = train_dataset.get_class_weights().to(DEVICE)
    print(f"ç±»åˆ«æƒé‡: {class_weights}")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, 
                             shuffle=True, num_workers=NUM_WORKERS, pin_memory=True,
                             drop_last=True)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, 
                           shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)
    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, 
                            shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)
    
    print(f"è®­ç»ƒé›†å¤§å°: {len(train_dataset)}")
    print(f"éªŒè¯é›†å¤§å°: {len(val_dataset)}")
    print(f"æµ‹è¯•é›†å¤§å°: {len(test_dataset)}")
    
    # åˆ›å»ºæ¨¡å‹
    print("æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹...")
    model = ImprovedResNetDR(num_classes=NUM_CLASSES, pretrained=True, dropout_rate=0.7)
    model = model.to(DEVICE)
    
    # ä½¿ç”¨æ··åˆæŸå¤±
    criterion = MixedLoss(alpha=0.7, class_weights=class_weights)
    
    # ä½¿ç”¨AdamWä¼˜åŒ–å™¨
    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-2)
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS, eta_min=1e-7)
    
    # è®­ç»ƒæ¨¡å‹
    print("å¼€å§‹è®­ç»ƒ...")
    train_losses, val_losses, train_accuracies, val_accuracies = train_model_with_early_stopping(
        model, train_loader, val_loader, criterion, optimizer, scheduler, NUM_EPOCHS, patience=3
    )
    
    # ç»˜åˆ¶è®­ç»ƒå†å²
    plot_training_history(train_losses, val_losses, train_accuracies, val_accuracies)
    
    # æµ‹è¯•
    print("æ­£åœ¨åŠ è½½æœ€ä½³æ¨¡å‹è¿›è¡Œæµ‹è¯•...")
    model.load_state_dict(torch.load(MODEL_SAVE_PATH))
    
    # ä½¿ç”¨TTAè¯„ä¼°æ¨¡å‹
    test_accuracy, predictions, true_labels, report = evaluate_model_with_tta(model, test_loader, num_tta=3)
    
    print(f"\nğŸ¯ æµ‹è¯•å‡†ç¡®ç‡ (TTA): {test_accuracy:.4f}")
    print("\nåˆ†ç±»æŠ¥å‘Š:")
    class_names = ['æ— ç—…å˜', 'è½»åº¦', 'ä¸­åº¦', 'é‡åº¦', 'å¢æ®–æ€§']
    for i, class_name in enumerate(class_names):
        if str(i) in report:
            precision = report[str(i)]['precision']
            recall = report[str(i)]['recall']
            f1_score = report[str(i)]['f1-score']
            print(f"{class_name}: ç²¾ç¡®ç‡={precision:.3f}, å¬å›ç‡={recall:.3f}, F1åˆ†æ•°={f1_score:.3f}")
    
    # ç»˜åˆ¶æ··æ·†çŸ©é˜µ
    plot_confusion_matrix(true_labels, predictions)
    
    print("æ”¹è¿›è®­ç»ƒå®Œæˆï¼")

def plot_training_history(train_losses, val_losses, train_accuracies, val_accuracies):
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
    
    ax1.plot(train_losses, label='è®­ç»ƒæŸå¤±', color='blue')
    ax1.plot(val_losses, label='éªŒè¯æŸå¤±', color='red')
    ax1.set_title('è®­ç»ƒå’ŒéªŒè¯æŸå¤±')
    ax1.set_xlabel('è½®æ¬¡')
    ax1.set_ylabel('æŸå¤±')
    ax1.legend()
    ax1.grid(True)
    
    ax2.plot(train_accuracies, label='è®­ç»ƒå‡†ç¡®ç‡', color='blue')
    ax2.plot(val_accuracies, label='éªŒè¯å‡†ç¡®ç‡', color='red')
    ax2.set_title('è®­ç»ƒå’ŒéªŒè¯å‡†ç¡®ç‡')
    ax2.set_xlabel('è½®æ¬¡')
    ax2.set_ylabel('å‡†ç¡®ç‡ (%)')
    ax2.legend()
    ax2.grid(True)
    
    plt.tight_layout()
    plt.savefig('improved_training_history.png', dpi=300, bbox_inches='tight')
    plt.show()

def plot_confusion_matrix(true_labels, predictions):
    class_names = ['æ— ç—…å˜', 'è½»åº¦', 'ä¸­åº¦', 'é‡åº¦', 'å¢æ®–æ€§']
    cm = confusion_matrix(true_labels, predictions)
    
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=class_names, yticklabels=class_names)
    plt.title('æ”¹è¿›æ¨¡å‹æ··æ·†çŸ©é˜µ')
    plt.xlabel('é¢„æµ‹æ ‡ç­¾')
    plt.ylabel('çœŸå®æ ‡ç­¾')
    plt.tight_layout()
    plt.savefig('improved_confusion_matrix.png', dpi=300, bbox_inches='tight')
    plt.show()

if __name__ == "__main__":
    main()
